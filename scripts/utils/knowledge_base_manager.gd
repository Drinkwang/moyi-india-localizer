## çŸ¥è¯†åº“ç®¡ç†å™¨
## 
## åŠŸèƒ½ï¼š
## - æœ¬åœ°æœ¯è¯­åº“ç®¡ç†
## - æ™ºèƒ½æ£€ç´¢å’ŒåŒ¹é…
## - ç¿»è¯‘æç¤ºå¢å¼º
## - ä¸å¢åŠ æ¨¡å‹ä¸Šä¸‹æ–‡è´Ÿæ‹…

class_name KnowledgeBaseManager
extends RefCounted

# å†…å­˜ç¼“å­˜
var _term_cache: Dictionary = {}
var _context_rules: Array = []
var _hot_terms: Dictionary = {}

# åŠ¨æ€è·¯å¾„é…ç½®
var _config_manager: ConfigManager
var _kb_root_dir: String
var _documents_dir: String
var _index_dir: String
var _cache_dir: String

## åˆå§‹åŒ–çŸ¥è¯†åº“
func initialize(config_manager: ConfigManager = null):
	if config_manager:
		_config_manager = config_manager
	else:
		_config_manager = ConfigManager.new()
	
	# æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å¯ç”¨
	if not _config_manager.is_knowledge_base_enabled():
		print("â„¹ï¸ çŸ¥è¯†åº“åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
		return
	
	_update_paths()
	_ensure_directories()
	_load_cache()
	_load_context_rules()
	
	# å¦‚æœç¼“å­˜ä¸ºç©ºï¼Œè‡ªåŠ¨æ‰«æå¹¶å¯¼å…¥ç°æœ‰çš„æœ¯è¯­æ–‡ä»¶
	if _term_cache.is_empty():
		_auto_import_existing_files()
	
	print("âœ… çŸ¥è¯†åº“ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œè·¯å¾„: ", _kb_root_dir, "ï¼Œæœ¯è¯­æ•°é‡: ", _term_cache.size())

## è‡ªåŠ¨å¯¼å…¥ç°æœ‰çš„æœ¯è¯­æ–‡ä»¶
func _auto_import_existing_files():
	print("ğŸ” æ‰«æç°æœ‰æœ¯è¯­æ–‡ä»¶...")
	
	# æ‰«æçŸ¥è¯†åº“æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰æœ¯è¯­æ–‡ä»¶
	var files_to_import = []
	_scan_directory_for_terms(_kb_root_dir, files_to_import)
	
	if files_to_import.is_empty():
		print("â„¹ï¸ æœªæ‰¾åˆ°ç°æœ‰æœ¯è¯­æ–‡ä»¶")
		return
	
	print("ğŸ“¥ å‘ç° ", files_to_import.size(), " ä¸ªæœ¯è¯­æ–‡ä»¶ï¼Œå¼€å§‹å¯¼å…¥...")
	
	for file_info in files_to_import:
		var file_path = file_info.path
		var category = file_info.category
		
		print("  å¯¼å…¥æ–‡ä»¶: ", file_path)
		var result = import_document(file_path, category)
		if result.success:
			print("  âœ… å¯¼å…¥æˆåŠŸ")
		else:
			print("  âŒ å¯¼å…¥å¤±è´¥: ", result.error)

## é€’å½’æ‰«æç›®å½•æŸ¥æ‰¾æœ¯è¯­æ–‡ä»¶
func _scan_directory_for_terms(dir_path: String, files_array: Array):
	var dir = DirAccess.open(dir_path)
	if not dir:
		return
	
	dir.list_dir_begin()
	var file_name = dir.get_next()
	
	while file_name != "":
		if file_name.begins_with("."):
			file_name = dir.get_next()
			continue
		
		var full_path = dir_path + "/" + file_name
		
		if dir.current_is_dir():
			# é€’å½’æ‰«æå­ç›®å½•
			_scan_directory_for_terms(full_path, files_array)
		else:
			# æ£€æŸ¥æ˜¯å¦æ˜¯æ”¯æŒçš„æœ¯è¯­æ–‡ä»¶
			var extension = file_name.get_extension().to_lower()
			if extension in ["txt", "csv", "json"]:
				var category = "game_terms"
				
				# æ ¹æ®è·¯å¾„ç¡®å®šåˆ†ç±»
				if "technical" in dir_path.to_lower():
					category = "technical_docs"
				elif "style" in dir_path.to_lower():
					category = "style_guides"
				
				files_array.append({
					"path": full_path,
					"category": category
				})
		
		file_name = dir.get_next()

## æ›´æ–°è·¯å¾„é…ç½®
func _update_paths():
	_kb_root_dir = _config_manager.get_knowledge_base_root_path()
	_documents_dir = _kb_root_dir + "documents/"
	_index_dir = _kb_root_dir + "index/"
	_cache_dir = _kb_root_dir + "cache/"

## ç¡®ä¿ç›®å½•å­˜åœ¨
func _ensure_directories():
	var dirs = [_kb_root_dir, _documents_dir, _index_dir, _cache_dir,
				_documents_dir + "game_terms/",
				_documents_dir + "technical_docs/",
				_documents_dir + "style_guides/"]
	
	for dir_path in dirs:
		if not DirAccess.dir_exists_absolute(dir_path):
			DirAccess.make_dir_recursive_absolute(dir_path)
			print("ğŸ“ åˆ›å»ºç›®å½•: ", dir_path)

## å¯¼å…¥æœ¯è¯­æ–‡æ¡£
func import_document(file_path: String, category: String = "game_terms") -> Dictionary:
	print("ğŸ“¥ å¼€å§‹å¯¼å…¥æ–‡æ¡£: ", file_path)
	
	var file = FileAccess.open(file_path, FileAccess.READ)
	if not file:
		return {"success": false, "error": "æ— æ³•æ‰“å¼€æ–‡ä»¶"}
	
	var content = file.get_as_text()
	file.close()
	
	# æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è§£ææ–¹å¼
	var terms = []
	var extension = file_path.get_extension().to_lower()
	
	match extension:
		"csv":
			terms = _parse_csv_terms(content)
		"json":
			terms = _parse_json_terms(content)
		"txt":
			terms = _parse_txt_terms(content)
		_:
			return {"success": false, "error": "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"}
	
	if terms.is_empty():
		return {"success": false, "error": "æœªæ‰¾åˆ°æœ‰æ•ˆæœ¯è¯­"}
	
	# ä¿å­˜åˆ°çŸ¥è¯†åº“
	var kb_file_path = _documents_dir + category + "/" + file_path.get_file().get_basename() + ".json"
	var result = _save_terms_to_kb(kb_file_path, terms, category)
	
	if result.success:
		_update_index(terms, category)
		print("âœ… æˆåŠŸå¯¼å…¥ ", terms.size(), " ä¸ªæœ¯è¯­")
	
	return result

## è§£æCSVæœ¯è¯­
func _parse_csv_terms(content: String) -> Array:
	var terms = []
	var lines = content.split("\n")
	
	# å‡è®¾CSVæ ¼å¼ï¼šsource,zh,en,ja,ru
	for i in range(1, lines.size()):  # è·³è¿‡æ ‡é¢˜è¡Œ
		var line = lines[i].strip_edges()
		if line.is_empty():
			continue
		
		var parts = line.split(",")
		if parts.size() >= 3:
			var term = {
				"source": parts[0].strip_edges(),
				"target": {},
				"context": [],
				"confidence": 1.0,
				"frequency": 1
			}
			
			# æå–å„è¯­è¨€ç¿»è¯‘
			if parts.size() > 1 and not parts[1].is_empty():
				term.target["zh"] = parts[1].strip_edges()
			if parts.size() > 2 and not parts[2].is_empty():
				term.target["en"] = parts[2].strip_edges()
			if parts.size() > 3 and not parts[3].is_empty():
				term.target["ja"] = parts[3].strip_edges()
			if parts.size() > 4 and not parts[4].is_empty():
				term.target["ru"] = parts[4].strip_edges()
			
			terms.append(term)
	
	return terms

## è§£æJSONæœ¯è¯­
func _parse_json_terms(content: String) -> Array:
	var json = JSON.new()
	var parse_result = json.parse(content)
	
	if parse_result != OK:
		print("âŒ JSONè§£æå¤±è´¥: ", json.get_error_message())
		return []
	
	var data = json.data
	if data is Dictionary and data.has("terms"):
		var terms_data = data.terms
		
		# å¦‚æœæ˜¯Dictionaryæ ¼å¼ï¼ˆç¼“å­˜æ–‡ä»¶ï¼‰ï¼Œè½¬æ¢ä¸ºArray
		if terms_data is Dictionary:
			var terms_array = []
			for key in terms_data.keys():
				terms_array.append(terms_data[key])
			return terms_array
		# å¦‚æœæ˜¯Arrayæ ¼å¼ï¼ˆåŸå§‹æ–‡ä»¶ï¼‰ï¼Œç›´æ¥è¿”å›
		elif terms_data is Array:
			return terms_data
	elif data is Array:
		return data
	
	return []

## è§£æTXTæœ¯è¯­
func _parse_txt_terms(content: String) -> Array:
	var terms = []
	var lines = content.split("\n")
	
	# æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
	# 1. ç®€å•æ ¼å¼ï¼šsource = target
	# 2. å¤šè¯­è¨€æ ¼å¼ï¼šsource = {"en": "è‹±æ–‡", "ja": "æ—¥æ–‡", "ru": "ä¿„æ–‡", "zh-TW": "ç¹ä½“ä¸­æ–‡"}
	for line in lines:
		line = line.strip_edges()
		if line.is_empty() or line.begins_with("#"):
			continue
		
		var parts = line.split("=", false, 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªç­‰å·
		if parts.size() == 2:
			var source_text = parts[0].strip_edges()
			var target_text = parts[1].strip_edges()
			
			var term = {
				"source": source_text,
				"target": {},
				"context": [],
				"confidence": 0.8,
				"frequency": 1
			}
			
			# æ£€æŸ¥æ˜¯å¦æ˜¯JSONæ ¼å¼çš„å¤šè¯­è¨€ç¿»è¯‘
			if target_text.begins_with("{") and target_text.ends_with("}"):
				# è§£æJSONæ ¼å¼çš„å¤šè¯­è¨€ç¿»è¯‘
				var json = JSON.new()
				var parse_result = json.parse(target_text)
				
				if parse_result == OK and json.data is Dictionary:
					term.target = json.data
					print("âœ… è§£æå¤šè¯­è¨€æœ¯è¯­: ", source_text, " -> ", json.data)
				else:
					print("âŒ JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ ¼å¼: ", target_text)
					# å¦‚æœJSONè§£æå¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æ ¼å¼
					var target_lang = _detect_language(target_text)
					term.target[target_lang] = target_text
			else:
				# ç®€å•æ ¼å¼ï¼šæ™ºèƒ½æ£€æµ‹ç›®æ ‡è¯­è¨€
				var target_lang = _detect_language(target_text)
				term.target[target_lang] = target_text
			
			terms.append(term)
	
	return terms

## ç®€å•çš„è¯­è¨€æ£€æµ‹å‡½æ•°
func _detect_language(text: String) -> String:
	# æ£€æµ‹æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
	var has_chinese = false
	for i in range(text.length()):
		var char_code = text.unicode_at(i)
		# ä¸­æ–‡å­—ç¬¦èŒƒå›´ï¼š0x4E00-0x9FFF
		if char_code >= 0x4E00 and char_code <= 0x9FFF:
			has_chinese = true
			break
	
	# å¦‚æœåŒ…å«ä¸­æ–‡ï¼Œè¿”å›ä¸­æ–‡ä»£ç 
	if has_chinese:
		return "zh"
	
	# å¦åˆ™å‡è®¾æ˜¯è‹±æ–‡
	return "en"

## ä¿å­˜æœ¯è¯­åˆ°çŸ¥è¯†åº“
func _save_terms_to_kb(file_path: String, terms: Array, category: String) -> Dictionary:
	var kb_data = {
		"metadata": {
			"version": "1.0",
			"last_updated": Time.get_datetime_string_from_system(),
			"category": category,
			"term_count": terms.size()
		},
		"terms": terms
	}
	
	var file = FileAccess.open(file_path, FileAccess.WRITE)
	if not file:
		return {"success": false, "error": "æ— æ³•åˆ›å»ºçŸ¥è¯†åº“æ–‡ä»¶"}
	
	file.store_string(JSON.stringify(kb_data, "\t"))
	file.close()
	
	return {"success": true, "file_path": file_path}

## æ›´æ–°ç´¢å¼•
func _update_index(terms: Array, category: String):
	# æ›´æ–°æœ¯è¯­æ˜ å°„ç´¢å¼•
	for term in terms:
		var source = term.source.to_lower()
		_term_cache[source] = term
		
		# æ›´æ–°é¢‘ç‡ç»Ÿè®¡
		if _hot_terms.has(source):
			_hot_terms[source] += 1
		else:
			_hot_terms[source] = 1
	
	# ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶
	_save_index()

## æ™ºèƒ½æ£€ç´¢æœ¯è¯­
func search_terms(query: String, max_results: int = 5) -> Array:
	# æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å¯ç”¨
	if not _config_manager or not _config_manager.is_knowledge_base_enabled():
		return []
	
	var results = []
	var query_lower = query.to_lower()
	
	# 1. ç²¾ç¡®åŒ¹é…
	if _term_cache.has(query_lower):
		results.append({
			"term": _term_cache[query_lower],
			"match_type": "exact",
			"confidence": 1.0
		})
	
	# 2. æ¨¡ç³ŠåŒ¹é…
	for term_key in _term_cache.keys():
		if results.size() >= max_results:
			break
		
		# è·³è¿‡å·²ç»ç²¾ç¡®åŒ¹é…çš„
		if term_key == query_lower:
			continue
		
		var similarity = _calculate_similarity(query_lower, term_key)
		if similarity > 0.6:  # ç›¸ä¼¼åº¦é˜ˆå€¼
			results.append({
				"term": _term_cache[term_key],
				"match_type": "fuzzy",
				"confidence": similarity
			})
	
	# 3. æŒ‰ç½®ä¿¡åº¦æ’åº
	results.sort_custom(func(a, b): return a.confidence > b.confidence)
	
	return results.slice(0, max_results)

## è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆç¼–è¾‘è·ç¦»ï¼‰
func _calculate_similarity(str1: String, str2: String) -> float:
	var len1 = str1.length()
	var len2 = str2.length()
	
	if len1 == 0 or len2 == 0:
		return 0.0
	
	# ç®€åŒ–ç‰ˆï¼šåŸºäºå…¬å…±å­ä¸²é•¿åº¦
	var common_chars = 0
	var min_len = min(len1, len2)
	
	for i in range(min_len):
		if str1[i] == str2[i]:
			common_chars += 1
		else:
			break
	
	# æ£€æŸ¥åŒ…å«å…³ç³»
	if str1 in str2 or str2 in str1:
		return 0.8
	
	return float(common_chars) / float(max(len1, len2))

## ä¸ºç¿»è¯‘å¢å¼ºæç¤º
func enhance_prompt(source_text: String, source_lang: String, target_lang: String, base_prompt: String) -> String:
	print("=== çŸ¥è¯†åº“å¢å¼ºæç¤ºè¯è°ƒè¯• ===")
	print("æºæ–‡æœ¬: ", source_text)
	print("æºè¯­è¨€: ", source_lang)
	print("ç›®æ ‡è¯­è¨€: ", target_lang)
	
	# æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å¯ç”¨
	if not _config_manager or not _config_manager.is_knowledge_base_enabled():
		print("âŒ çŸ¥è¯†åº“æœªå¯ç”¨ï¼Œè¿”å›åŸå§‹æç¤ºè¯")
		return base_prompt
	
	var search_results = search_terms(source_text, 3)
	print("æœç´¢ç»“æœæ•°é‡: ", search_results.size())
	
	if search_results.is_empty():
		print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æœ¯è¯­ï¼Œè¿”å›åŸå§‹æç¤ºè¯")
		return base_prompt
	
	var enhancement = "\n\nå‚è€ƒæœ¯è¯­åº“ï¼š"
	var has_enhancement = false
	
	for result in search_results:
		var term = result.term
		print("æ£€æŸ¥æœ¯è¯­: ", term.source, " -> ", term.target)
		if term.target.has(target_lang):
			enhancement += "\n- \"" + term.source + "\" â†’ \"" + term.target[target_lang] + "\""
			has_enhancement = true
			print("âœ… æ·»åŠ æœ¯è¯­: ", term.source, " -> ", term.target[target_lang])
		else:
			print("âŒ æœ¯è¯­æ²¡æœ‰ç›®æ ‡è¯­è¨€ç¿»è¯‘: ", target_lang)
	
	if has_enhancement:
		enhancement += "\nè¯·å‚è€ƒä¸Šè¿°æœ¯è¯­ä¿æŒç¿»è¯‘ä¸€è‡´æ€§ã€‚"
		var enhanced_prompt = base_prompt + enhancement
		print("âœ… å¢å¼ºåçš„æç¤ºè¯:")
		print("åŸå§‹æç¤ºè¯: ", base_prompt)
		print("å¢å¼ºéƒ¨åˆ†: ", enhancement)
		print("å®Œæ•´æç¤ºè¯: ", enhanced_prompt)
		print("=============================")
		return enhanced_prompt
	
	print("âŒ æ²¡æœ‰å¯ç”¨çš„æœ¯è¯­å¢å¼ºï¼Œè¿”å›åŸå§‹æç¤ºè¯")
	print("=============================")
	return base_prompt

## åŠ è½½ç¼“å­˜ï¼ˆå¸¦æ–‡ä»¶å˜åŒ–æ£€æµ‹ï¼‰
func _load_cache():
	var cache_file = _cache_dir + "term_cache.json"
	var should_reload = false
	
	if FileAccess.file_exists(cache_file):
		var file = FileAccess.open(cache_file, FileAccess.READ)
		if file:
			var json = JSON.new()
			var parse_result = json.parse(file.get_as_text())
			file.close()
			
			if parse_result == OK and json.data is Dictionary:
				var cache_data = json.data
				_term_cache = cache_data.get("terms", {})
				_hot_terms = cache_data.get("hot_terms", {})
				
				# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å˜åŒ–
				var cached_file_info = cache_data.get("file_info", {})
				var current_file_info = _get_files_modification_info()
				
				should_reload = _has_files_changed(cached_file_info, current_file_info)
				
				if should_reload:
					print("ğŸ”„ æ£€æµ‹åˆ°æœ¯è¯­æ–‡ä»¶å˜åŒ–ï¼Œé‡æ–°åŠ è½½...")
					_term_cache.clear()
					_hot_terms.clear()
				else:
					print("ğŸ“‹ å·²åŠ è½½ç¼“å­˜: ", _term_cache.size(), " ä¸ªæœ¯è¯­")
	else:
		should_reload = true
	
	# å¦‚æœéœ€è¦é‡æ–°åŠ è½½ï¼Œè‡ªåŠ¨å¯¼å…¥æ–‡ä»¶
	if should_reload:
		_auto_import_existing_files()

## åŠ è½½ä¸Šä¸‹æ–‡è§„åˆ™
func _load_context_rules():
	var rules_file = _index_dir + "context_rules.json"
	if FileAccess.file_exists(rules_file):
		var file = FileAccess.open(rules_file, FileAccess.READ)
		if file:
			var json = JSON.new()
			var parse_result = json.parse(file.get_as_text())
			file.close()
			
			if parse_result == OK and json.data is Dictionary:
				_context_rules = json.data.get("rules", [])

## ä¿å­˜ç´¢å¼•
func _save_index():
	var index_data = {
		"terms": _term_cache,
		"hot_terms": _hot_terms,
		"last_updated": Time.get_datetime_string_from_system(),
		"file_info": _get_files_modification_info()
	}
	
	var file = FileAccess.open(_cache_dir + "term_cache.json", FileAccess.WRITE)
	if file:
		file.store_string(JSON.stringify(index_data, "\t"))
		file.close()

## è·å–ç»Ÿè®¡ä¿¡æ¯
func get_statistics() -> Dictionary:
	return {
		"total_terms": _term_cache.size(),
		"hot_terms_count": _hot_terms.size(),
		"cache_hit_rate": 0.895,  # æ¨¡æ‹Ÿæ•°æ®
		"last_updated": Time.get_datetime_string_from_system()
	}

## æ¸…ç†ç¼“å­˜
func clear_cache():
	_term_cache.clear()
	_hot_terms.clear()
	
	var cache_file = _cache_dir + "term_cache.json"
	if FileAccess.file_exists(cache_file):
		DirAccess.remove_absolute(cache_file)
	
	print("ğŸ—‘ï¸ ç¼“å­˜å·²æ¸…ç†")

## æ›´æ”¹çŸ¥è¯†åº“è·¯å¾„ï¼ˆæ”¯æŒæ•°æ®è¿ç§»ï¼‰
func change_knowledge_base_path(new_path: String, migrate_data: bool = true) -> Dictionary:
	var old_path = _kb_root_dir
	var result = {"success": false, "error": "", "migrated_files": 0}
	
	# éªŒè¯æ–°è·¯å¾„
	if new_path.is_empty():
		result.error = "è·¯å¾„ä¸èƒ½ä¸ºç©º"
		return result
	
	# ç¡®ä¿è·¯å¾„ä»¥/ç»“å°¾
	if not new_path.ends_with("/"):
		new_path += "/"
	
	# æ›´æ–°é…ç½®
	if not _config_manager.set_knowledge_base_root_path(new_path):
		result.error = "é…ç½®ä¿å­˜å¤±è´¥"
		return result
	
	# å¦‚æœéœ€è¦è¿ç§»æ•°æ®
	if migrate_data and DirAccess.dir_exists_absolute(old_path):
		var migration_result = _migrate_knowledge_base_data(old_path, new_path)
		result.migrated_files = migration_result.migrated_files
		if not migration_result.success:
			result.error = "æ•°æ®è¿ç§»å¤±è´¥: " + migration_result.error
			return result
	
	# æ›´æ–°è·¯å¾„å¹¶é‡æ–°åˆå§‹åŒ–
	_update_paths()
	_ensure_directories()
	_load_cache()
	_load_context_rules()
	
	result.success = true
	print("âœ… çŸ¥è¯†åº“è·¯å¾„å·²æ›´æ”¹ä¸º: ", new_path)
	
	return result

## è¿ç§»çŸ¥è¯†åº“æ•°æ®
func _migrate_knowledge_base_data(old_path: String, new_path: String) -> Dictionary:
	var result = {"success": false, "error": "", "migrated_files": 0}
	
	# åˆ›å»ºæ–°ç›®å½•
	if not DirAccess.make_dir_recursive_absolute(new_path):
		result.error = "æ— æ³•åˆ›å»ºæ–°ç›®å½•"
		return result
	
	# å¤åˆ¶æ–‡ä»¶
	var dir = DirAccess.open(old_path)
	if not dir:
		result.error = "æ— æ³•è®¿é—®æ—§ç›®å½•"
		return result
	
	var copy_result = _copy_directory_recursive(old_path, new_path)
	result.migrated_files = copy_result.copied_files
	
	if copy_result.success:
		result.success = true
		print("ğŸ“¦ å·²è¿ç§» ", result.migrated_files, " ä¸ªæ–‡ä»¶")
	else:
		result.error = copy_result.error
	
	return result

## é€’å½’å¤åˆ¶ç›®å½•
func _copy_directory_recursive(source_dir: String, target_dir: String) -> Dictionary:
	var result = {"success": false, "error": "", "copied_files": 0}
	
	var source = DirAccess.open(source_dir)
	if not source:
		result.error = "æ— æ³•æ‰“å¼€æºç›®å½•"
		return result
	
	# ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
	DirAccess.make_dir_recursive_absolute(target_dir)
	
	source.list_dir_begin()
	var file_name = source.get_next()
	
	while file_name != "":
		var source_path = source_dir + "/" + file_name
		var target_path = target_dir + "/" + file_name
		
		if source.current_is_dir():
			# é€’å½’å¤åˆ¶å­ç›®å½•
			var sub_result = _copy_directory_recursive(source_path, target_path)
			result.copied_files += sub_result.copied_files
			if not sub_result.success:
				result.error = sub_result.error
				return result
		else:
			# å¤åˆ¶æ–‡ä»¶
			if source.copy(source_path, target_path) == OK:
				result.copied_files += 1
			else:
				result.error = "å¤åˆ¶æ–‡ä»¶å¤±è´¥: " + file_name
				return result
		
		file_name = source.get_next()
	
	result.success = true
	return result

## è·å–å½“å‰çŸ¥è¯†åº“è·¯å¾„
func get_current_path() -> String:
	return _kb_root_dir

## éªŒè¯çŸ¥è¯†åº“è·¯å¾„
func validate_path(path: String) -> Dictionary:
	var result = {"valid": false, "error": "", "writable": false, "has_data": false}
	
	if path.is_empty():
		result.error = "è·¯å¾„ä¸èƒ½ä¸ºç©º"
		return result
	
	# æ£€æŸ¥è·¯å¾„æ˜¯å¦å¯è®¿é—®
	var dir = DirAccess.open(path)
	if not dir:
		# å°è¯•åˆ›å»ºç›®å½•
		if DirAccess.make_dir_recursive_absolute(path) != OK:
			result.error = "æ— æ³•åˆ›å»ºæˆ–è®¿é—®è¯¥è·¯å¾„"
			return result
		dir = DirAccess.open(path)
	
	# æ£€æŸ¥æ˜¯å¦å¯å†™
	var test_file = path + "/test_write.tmp"
	var file = FileAccess.open(test_file, FileAccess.WRITE)
	if file:
		file.store_string("test")
		file.close()
		DirAccess.remove_absolute(test_file)
		result.writable = true
	else:
		result.error = "ç›®å½•ä¸å¯å†™"
		return result
	
	# æ£€æŸ¥æ˜¯å¦å·²æœ‰çŸ¥è¯†åº“æ•°æ®
	if DirAccess.dir_exists_absolute(path + "/documents/") or DirAccess.dir_exists_absolute(path + "/index/"):
		result.has_data = true
	
	result.valid = true
	return result

## è·å–æ‰€æœ‰æœ¯è¯­æ–‡ä»¶çš„ä¿®æ”¹ä¿¡æ¯
func _get_files_modification_info() -> Dictionary:
	var file_info = {}
	var files_to_check = []
	
	# æ‰«ææ‰€æœ‰æœ¯è¯­æ–‡ä»¶
	_scan_directory_for_terms(_kb_root_dir, files_to_check)
	
	for file_data in files_to_check:
		var file_path = file_data.path
		if FileAccess.file_exists(file_path):
			# è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´å’Œå¤§å°
			var modified_time = FileAccess.get_modified_time(file_path)
			var file_access = FileAccess.open(file_path, FileAccess.READ)
			var file_size = 0
			if file_access:
				file_size = file_access.get_length()
				file_access.close()
			
			# ä½¿ç”¨ç›¸å¯¹è·¯å¾„ä½œä¸ºkeyï¼Œä¿æŒä¸€è‡´æ€§
			var relative_path = file_path.replace(_kb_root_dir, "data/knowledge_base/")
			file_info[relative_path] = {
				"modified_time": modified_time,
				"size": file_size
			}
	
	return file_info

## æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å˜åŒ–
func _has_files_changed(cached_info: Dictionary, current_info: Dictionary) -> bool:
	# æ£€æŸ¥æ–‡ä»¶æ•°é‡æ˜¯å¦å˜åŒ–
	if cached_info.size() != current_info.size():
		return true
	
	# æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´å’Œå¤§å°
	for file_path in current_info.keys():
		if not cached_info.has(file_path):
			return true  # æ–°æ–‡ä»¶
		
		var cached_file = cached_info[file_path]
		var current_file = current_info[file_path]
		
		if cached_file.modified_time != current_file.modified_time or \
		   cached_file.size != current_file.size:
			return true  # æ–‡ä»¶å·²ä¿®æ”¹
	
	# æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶è¢«åˆ é™¤
	for file_path in cached_info.keys():
		if not current_info.has(file_path):
			return true  # æ–‡ä»¶è¢«åˆ é™¤
	
	return false
